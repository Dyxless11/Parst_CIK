{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from operator import itemgetter, attrgetter\n",
    "from PIL import Image\n",
    "import glob\n",
    "from tensorflow import keras\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation, BatchNormalization, AveragePooling2D\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop, Adam\n",
    "# import tensorflow_datasets as tfds  # pip install tensorflow-datasets\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chrome_options = Options()\n",
    "# chrome_options.add_argument(\"--headless\")\n",
    "driver = webdriver.Chrome('path/chromedriver')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Собираем 1000 капч"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1000\n",
    "while i>0:\n",
    "    driver.get('http://www.vybory.izbirkom.ru/region/izbirkom?action=show&vrn=4274007421995&region=27&prver=0&pronetvd=0')\n",
    "    time.sleep(0.5)\n",
    "    with open(str(i)+'.png', 'wb') as file:\n",
    "        file.write(driver.find_element_by_xpath('//*[@id=\"captchaImg\"]').screenshot_as_png)\n",
    "    i = i - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нарезаем капчу по цифрам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_img = glob.glob('path/*.png')\n",
    "\n",
    "for img in list_img:\n",
    "    im = Image.open(img)\n",
    "    im = im.convert(\"P\")\n",
    "    im2 = Image.new(\"P\",im.size,255)\n",
    "\n",
    "    im = im.convert(\"P\")\n",
    "\n",
    "    temp = {}\n",
    "\n",
    "    for x in range(im.size[1]):\n",
    "        for y in range(im.size[0]):\n",
    "            pix = im.getpixel((y,x))\n",
    "            temp[pix] = pix\n",
    "            if pix != 0: \n",
    "                im2.putpixel((y,x),0)\n",
    "\n",
    "    im2.save(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# обрезаем нарезанные числа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in glob.glob('path/*.png'):\n",
    "    im2 = Image.open(name)\n",
    "    resized_img = im2.resize((10, 50), Image.ANTIALIAS)\n",
    "    im3 = resized_img.transpose(Image.ROTATE_90)\n",
    "    letters = []\n",
    "\n",
    "    for y in range(im3.size[0]): # slice across\n",
    "        for x in range(im3.size[1]): # slice down\n",
    "            pix = im3.getpixel((y,x))\n",
    "            if pix != 255:\n",
    "                inletter = True\n",
    "        if foundletter == False and inletter == True:\n",
    "            foundletter = True\n",
    "            start = y\n",
    "\n",
    "        if foundletter == True and inletter == False:\n",
    "            foundletter = False\n",
    "            end = y\n",
    "            letters.append((start,end))\n",
    "\n",
    "        inletter=False\n",
    "    print (letters)\n",
    "    for letter in letters:\n",
    "        im4 = im3.crop(( letter[0] , 0, letter[1],im3.size[1] ))\n",
    "    im4 = im4.transpose(Image.ROTATE_270)\n",
    "    im4.save(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_folder = ['0','1','2','3','4','5','6','7','8','9']\n",
    "X_Train = []\n",
    "y_train = []\n",
    "for folder in list_folder:\n",
    "    for name in glob.glob('/Users/aleksejkudrasov/Downloads/solving_captchas_code_examples/resize/'+folder+'/*.png'):\n",
    "        im2 = Image.open(name)\n",
    "        resized_img = im2.resize((10, 10), Image.ANTIALIAS)\n",
    "        X_Train.append(np.array(resized_img))\n",
    "        y_train.append(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train = np.array(X_Train) / 255.0\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_Train, y_train, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = X_train.reshape(X_train.shape[0], 10*10)\n",
    "test_data = X_test.reshape(X_test.shape[0], 10*10)\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_cat = keras.utils.to_categorical(y_train, num_classes)\n",
    "test_labels_cat = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_make_model(image_w: int, image_h: int):\n",
    "    # Neural network model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(image_w*image_h, activation='relu', input_shape=(image_w*image_h,)))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mnist_make_model(10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.6098e-09 - accuracy: 1.0000 - val_loss: 0.1056 - val_accuracy: 0.9867\n",
      "Epoch 2/20\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 5.3294e-09 - accuracy: 1.0000 - val_loss: 0.1049 - val_accuracy: 0.9867\n",
      "Epoch 3/20\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 5.1891e-09 - accuracy: 1.0000 - val_loss: 0.1051 - val_accuracy: 0.9867\n",
      "Epoch 4/20\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 4.9086e-09 - accuracy: 1.0000 - val_loss: 0.1044 - val_accuracy: 0.9867\n",
      "Epoch 5/20\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 5.3294e-09 - accuracy: 1.0000 - val_loss: 0.1049 - val_accuracy: 0.9867\n",
      "Epoch 6/20\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 5.3294e-09 - accuracy: 1.0000 - val_loss: 0.1051 - val_accuracy: 0.9867\n",
      "Epoch 7/20\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 5.1891e-09 - accuracy: 1.0000 - val_loss: 0.1046 - val_accuracy: 0.9867\n",
      "Epoch 8/20\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 5.6098e-09 - accuracy: 1.0000 - val_loss: 0.1056 - val_accuracy: 0.9867\n",
      "Epoch 9/20\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 5.0489e-09 - accuracy: 1.0000 - val_loss: 0.1055 - val_accuracy: 0.9867\n",
      "Epoch 10/20\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 5.3294e-09 - accuracy: 1.0000 - val_loss: 0.1052 - val_accuracy: 0.9867\n",
      "Epoch 11/20\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 5.3294e-09 - accuracy: 1.0000 - val_loss: 0.1049 - val_accuracy: 0.9867\n",
      "Epoch 12/20\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 5.8903e-09 - accuracy: 1.0000 - val_loss: 0.1054 - val_accuracy: 0.9867\n",
      "Epoch 13/20\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 5.8903e-09 - accuracy: 1.0000 - val_loss: 0.1062 - val_accuracy: 0.9867\n",
      "Epoch 14/20\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 4.9086e-09 - accuracy: 1.0000 - val_loss: 0.1052 - val_accuracy: 0.9867\n",
      "Epoch 15/20\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 5.6098e-09 - accuracy: 1.0000 - val_loss: 0.1059 - val_accuracy: 0.9867\n",
      "Epoch 16/20\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 5.4696e-09 - accuracy: 1.0000 - val_loss: 0.1053 - val_accuracy: 0.9867\n",
      "Epoch 17/20\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 5.7501e-09 - accuracy: 1.0000 - val_loss: 0.1061 - val_accuracy: 0.9867\n",
      "Epoch 18/20\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 5.3294e-09 - accuracy: 1.0000 - val_loss: 0.1052 - val_accuracy: 0.9867\n",
      "Epoch 19/20\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 4.9086e-09 - accuracy: 1.0000 - val_loss: 0.1062 - val_accuracy: 0.9867\n",
      "Epoch 20/20\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 5.4696e-09 - accuracy: 1.0000 - val_loss: 0.1069 - val_accuracy: 0.9867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8d46a66ac0>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, train_labels_cat, epochs=20, batch_size=32, verbose=1, validation_data=(test_data, test_labels_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
